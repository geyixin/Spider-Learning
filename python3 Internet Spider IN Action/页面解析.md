#  :hammer: 页面解析

+ :hamburger:[正则](#正则)
+ :orange:[xpath](#xpath) 
+ :apple:[Beautiful Soup](#Beautiful Soup)
+ :baseball:[pyquery](#pyquery)

## 正则

  > 可以用，但是比较繁杂，容易写错。

## xpath

  > xpath，全程XML Path Language，XML路径语言，在XML文档中查找信息的语言。同样适用于HTML文档的搜索。
  >
  > 爬虫中的页面解析：from lxml import etree
  >
  > ```python3
  > from lxml import etree
  > 
  > response3 = requests.get(url, headers=HEADERS)
  > content = etree.HTML(response3.text)
  > a = content.xpath("//div[@class='where']/span[2]/text()")
  > ```
  >
  > Xpath常用规则如下：
  >|  表达式  |           描述           |
  >| :------: | :----------------------: |
  >| nodename |  选取此节点的所有子节点  |
  >|     /     | 从当前节点选取直接子节点 |
  >|      //    |  从当前节点选取子孙节点  |
  >|      .    |       选取当前节点       |
  >|       ..   |   选取当前节点的父节点   |
  >|@|选取属性|
  >
  > 虽说Xpath很强大，但是对于现在多结构、多层级的网页来说xpath也显得捉襟见肘。

## Beautiful Soup

  > 减少解析工作量。
  >
  > ```python3
  > from bs4 import BeautifulSoup
  > soup = BeautifulSoup(html, 'lxml')
  > ```
  >
  > 1. 常用lxml解析库；
  > 2. 节点选择筛选功能弱，但，速度快；
  > 3. find() ，find_all()查询；
  > 4. select()选择。

## pyquery

> 适合于对CSS比较熟悉的盆友。
>
> ```python3
> from pyquery import PyQuery as pq
> html = 'xxxxxx'
> res = pq(html)  						             # 传递字符串
> # res = pq(url='https://www.baidu.com')  # 传递网址
> # res = pq(filename = 'test.html')	  	 # 传递文件
> print(res('li'))
> ```
